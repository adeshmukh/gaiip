{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRGNiP/MaG9hutuQqr742h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adeshmukh/gaiip/blob/main/notebooks/Intro_to_Guardrails_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ref: https://www.guardrailsai.com/docs/guardrails_ai/getting_started\n",
        "More examples at: https://github.com/guardrails-ai/guardrails/tree/main/docs/examples"
      ],
      "metadata": {
        "id": "Qr3OieF2Guc7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HOzDdo34i1NK"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install orjson==3.10.6\n!pip install guardrails-ai==0.5.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"GUARDRAILSAI_API_KEY\"] = userdata.get('GUARDRAILSAI_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "rFUL_lIpFY58"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure the GuardRails hub"
      ],
      "metadata": {
        "id": "avrmZb1TjUVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!guardrails configure --enable-metrics --enable-remote-inferencing --token \"${GUARDRAILSAI_API_KEY}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FKsdTxujNf8",
        "outputId": "2a74bfc6-9cdf-4f0c-c9f7-18c2ddf6db74"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "\n",
            "            Login successful.\n",
            "\n",
            "            Get started by installing our RegexMatch validator:\n",
            "            https://hub.guardrailsai.com/validator/guardrails_ai/regex_match\n",
            "\n",
            "            You can install it by running:\n",
            "            guardrails hub install hub://guardrails/regex_match\n",
            "\n",
            "            Find more validators at https://hub.guardrailsai.com\n",
            "            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!guardrails hub install hub://guardrails/regex_match       --quiet --install-local-models\n",
        "!guardrails hub install hub://guardrails/valid_length      --quiet --install-local-models\n",
        "!guardrails hub install hub://guardrails/toxic_language    --quiet --install-local-models\n",
        "# !guardrails hub install hub://guardrails/unusual_prompt    --quiet --install-local-models\n",
        "# !guardrails hub install hub://guardrails/reading_time      --quiet --install-local-models\n",
        "# !guardrails hub install hub://guardrails/politeness_check  --quiet --install-local-models\n",
        "# !guardrails hub install hub://guardrails/profanity_free    --quiet --install-local-models\n",
        "# !guardrails hub install hub://guardrails/restricttotopic   --quiet --install-local-models\n",
        "# !guardrails hub install hub://guardrails/competitor_check  --quiet --install-local-models\n",
        "# !guardrails hub install hub://guardrails/detect_pii        --quiet --install-local-models\n",
        "# !guardrails hub install hub://guardrails/financial_tone    --quiet --install-local-models"
      ],
      "metadata": {
        "id": "kTQUFkE2jXBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Guards\n",
        "\n",
        "Guards can be used as a general-purpose validation framework. This use by itself is not very interesting. But it's still useful to know for a couple of reasons:\n",
        "1. It is a gentle introduction to the concept of guards and their usage.\n",
        "2. It's somewhat useful to apply uniform paradigm for all types of validations in a Gen AI application."
      ],
      "metadata": {
        "id": "5BC--XaV0573"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Guard and Validator\n",
        "from guardrails.hub import RegexMatch\n",
        "from guardrails import Guard\n",
        "\n",
        "# Initialize the Guard with the regex\n",
        "guard = Guard().use(\n",
        "    RegexMatch(regex=\"^[A-Z][a-z]*$\")\n",
        ")\n",
        "\n",
        "# Guardrail passes\n",
        "validation_outcome = guard.parse(\"Caesar\")\n",
        "print(validation_outcome.model_dump_json(indent=2))\n",
        "\n",
        "# Guardrail fails\n",
        "validation_outcome = guard.parse(\"Caesar is a great leader\")\n",
        "print(validation_outcome.model_dump_json(indent=2))"
      ],
      "metadata": {
        "id": "pcZuXHFMEvxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating structured JSON output from LLM\n",
        "\n",
        "Often, in agentic interactions with LLM, it is desirable to ensure that the output conforms to a JSON structure. This can be achieved in a couple of different ways using Guardrails AI."
      ],
      "metadata": {
        "id": "4uR9SR6-2W1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's set up a simple pydantic model which will be used to constrain the LLM response."
      ],
      "metadata": {
        "id": "yu5D9jeo25VG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Pet(BaseModel):\n",
        "    pet_type: str = Field(description=\"Species of pet\")\n",
        "    name: str = Field(description=\"a unique pet name\")"
      ],
      "metadata": {
        "id": "N_G-2GmdE91Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Pydantic support in GuardrailsAI\n",
        "\n",
        "Encapsulating the LLM interaction with Guard. Guardrails has native support for pydantic objects.\n",
        "\n",
        "Note that this uses a prompt template with a [built-in constant](https://github.com/guardrails-ai/guardrails/blob/main/guardrails/constants.xml)."
      ],
      "metadata": {
        "id": "6CiZCA6o3Fv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from guardrails import Guard\n",
        "\n",
        "# NOTE: This is a prompt \"template\" with a parameter named \"gr.complete_xml_suffix_v2\", which resolves to a built-in constant.\n",
        "# Built-in constants are defined in guardrails/constants.xml\n",
        "prompt = \"\"\"\n",
        "    What kind of pet should I get and what should I name it?\n",
        "    I would like to have a pet that I can take with me to places I visit.\n",
        "\n",
        "    ${gr.complete_xml_suffix_v2}\n",
        "\"\"\"\n",
        "guard = Guard.from_pydantic(output_class=Pet)\n",
        "\n",
        "res = guard(\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    model=\"gpt-3.5-turbo\"\n",
        ")\n",
        "\n",
        "print(res.validated_output)"
      ],
      "metadata": {
        "id": "rVllU4JJFSfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## JSON output for tool invocations\n",
        "\n"
      ],
      "metadata": {
        "id": "r1BIRMh2Gxv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "from guardrails import Guard\n",
        "\n",
        "class Fruit(BaseModel):\n",
        "    name: str\n",
        "    color: str\n",
        "\n",
        "class Basket(BaseModel):\n",
        "    fruits: List[Fruit]\n",
        "\n",
        "guard = Guard.from_pydantic(Basket)\n"
      ],
      "metadata": {
        "id": "O4u-dAV4H4QJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = guard(\n",
        "    messages=[{\"role\":\"user\", \"content\":\"Generate a basket of 5 fruits\"}],\n",
        "    model=\"gpt-4o\",\n",
        "    tools=guard.json_function_calling_tool([]),\n",
        "    tool_choice=\"required\",\n",
        ")\n",
        "\n",
        "print(f\"{result.model_dump_json(indent=2)}\")"
      ],
      "metadata": {
        "id": "mQeRXD5I-gt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Structured Data\n",
        "Ref: https://www.guardrailsai.com/docs/how_to_guides/generate_structured_data\n"
      ],
      "metadata": {
        "id": "Njr40crPnQ4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from guardrails import Guard\n",
        "from guardrails.hub import RegexMatch\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "NAME_REGEX = \"^[A-Z][a-z]+\\s[A-Z][a-z]+$\"\n",
        "\n",
        "class Delivery(BaseModel):\n",
        "    customer_name: str=Field(validators=[RegexMatch(regex=NAME_REGEX)], description=\"customer name\")\n",
        "    pickup_time: str=Field(description=\"date and time of pickup\")\n",
        "    pickup_location: str=Field(description=\"address of pickup\")\n",
        "    dropoff_time: str=Field(description=\"date and time of dropoff\")\n",
        "    dropoff_location: str=Field(description=\"address of dropoff\")\n",
        "    price: str = Field(description=\"price of delivery with currency symbol included\")\n",
        "\n",
        "class Schedule(BaseModel):\n",
        "    deliveries: List[Delivery]\n",
        "\n",
        "guard = Guard.from_pydantic(Schedule)\n",
        "chat_history=\"\"\"\n",
        "nelson and murdock: i need a pickup 797 9th Avenue, manila envelope, June 3 10:00am with dropoff 10:30am Courthouse, 61 Center Street C/O frank james\n",
        "operator: quote - $23.00\n",
        "neslon and murdock: perfect, we accept the quote\n",
        "operator: 797 9th ave, 10:00am pickup comfirmed\n",
        "abc flowers: i need a pickup of a flowers from abc flowers at 21 3rd street at 11:00am on june 2 with a dropoff at 75th Ave at 5:30pm same day\n",
        "operator: 21 3rd street flowers quote - $14.50\n",
        "abc flowers: accepted\n",
        "polk and wardell: i need a pickup of a bagels from Bakers Co at 331 5th street at 11:00am on june 3 with a dropoff at 75th Ave at 5:30pm same day\n",
        "operator: 331 5th street bagels quote - $34.50\n",
        "polk and wardell: accepted\n",
        "\"\"\"\n",
        "\n",
        "# NOTE: This is a prompt template with parameter \"chat_history\".\n",
        "prompt = \"\"\"\n",
        "From the chat exchanges below extract a schedule of deliveries.\n",
        "Chats:\n",
        "${chat_history}\n",
        "\"\"\"\n",
        "\n",
        "messages = [{\n",
        "  \"role\": \"system\",\n",
        "  \"content\": \"You are a helpful assistant.\"\n",
        "}, {\n",
        "  \"role\": \"user\",\n",
        "  \"content\": prompt\n",
        "}]"
      ],
      "metadata": {
        "id": "pOnX5I1UnP5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's inspect the \"prompt\" and note that \"chat_history\" is not yet resolved.\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "O9KtcI5MozWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's take a peek at the \"messages\" with the \"prompt\"\n",
        "import json\n",
        "print(json.dumps(messages, indent=2))"
      ],
      "metadata": {
        "id": "tAJmK4cXpV6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Approach A: Using plain prompt engineering\n",
        "\n",
        "In this approach, the guard will use prompt engineering to get the output to conform to JSON structure."
      ],
      "metadata": {
        "id": "YM_E6Uv4njOQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "O42_8UHyn550"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: We are extending the prompt template.\n",
        "# Another template \"gr.complete_json_suffix_v3\" is added here.\n",
        "prompt+=\"\"\"\n",
        "\n",
        "${gr.complete_json_suffix_v3}\n",
        "\"\"\"\n",
        "validation_response = guard(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[messages[0],{\n",
        "      \"role\": \"user\",\n",
        "      \"content\": prompt\n",
        "    }],\n",
        "    prompt_params={\"chat_history\": chat_history},\n",
        ")"
      ],
      "metadata": {
        "id": "GYUxMvBeniii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(validation_response.model_dump_json(indent=2))"
      ],
      "metadata": {
        "id": "nQUMvOH2qE9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Approach B: JSON mode\n",
        "\n",
        "Some LLMs, like OpenAI provide native support for [JSON mode](https://platform.openai.com/docs/guides/json-mode). JSON mode ensures that the output from the LLM conforms to a valid JSON structure."
      ],
      "metadata": {
        "id": "hLgxSCr60ML9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages[-1][\"content\"]+=\"\"\"\n",
        "\n",
        "${gr.complete_json_suffix_v3}\n",
        "\"\"\"\n",
        "response = guard(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=messages,\n",
        "    prompt_params={\"chat_history\": chat_history},\n",
        "    response_format={ \"type\": \"json_object\" }\n",
        ")"
      ],
      "metadata": {
        "id": "_xrzhAC40KyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Approach C: Using function calling\n",
        "\n",
        "Some LLMs, like OpenAI provide native support for [function calling](https://platform.openai.com/docs/guides/function-calling). And function calling uses JSON mode, thus ensuring that the LLM invokes a function *and* returns a JSON response.\n",
        "\n",
        "In this case, we will configure the guard to use function calling."
      ],
      "metadata": {
        "id": "AkOV2VAOnqm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [] # an open ai compatible list of tools\n",
        "\n",
        "validation_response = guard(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=messages,\n",
        "    prompt_params={\"chat_history\": chat_history},\n",
        "    tools=guard.json_function_calling_tool(tools),\n",
        "    tool_choice=\"required\",\n",
        ")"
      ],
      "metadata": {
        "id": "vb2oQfXnnqEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(validation_response.model_dump_json(indent=2))"
      ],
      "metadata": {
        "id": "Pxg6X0SbrYnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Guarding against toxic language\n"
      ],
      "metadata": {
        "id": "38D_ESo5_BI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import the guardrails package\n",
        "# and the ToxicLanguage validator\n",
        "# from Guardrails Hub\n",
        "import guardrails as gd\n",
        "from guardrails.hub import ToxicLanguage\n",
        "from rich import print\n",
        "\n",
        "# Create a Guard object with this validator\n",
        "# Here, we'll use the default validation method of \"sentence\"\n",
        "# and the default threshold of 0.25\n",
        "\n",
        "guard = gd.Guard.from_string(\n",
        "    validators=[ToxicLanguage(on_fail=\"fix\")],\n",
        "    description=\"testmeout\",\n",
        ")"
      ],
      "metadata": {
        "id": "1Am1FhNTrajs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Parse the raw response\n",
        "raw_response = \"\"\"\n",
        "What a lovely day it has been to roam around the city. I love it here!\n",
        "I hate how pathetic and needy you can be sometimes.\n",
        "\"\"\"\n",
        "raw_llm_output, validated_output, *rest = guard.parse(\n",
        "    llm_output=raw_response,\n",
        ")\n",
        "\n",
        "# Print the output\n",
        "print(validated_output)"
      ],
      "metadata": {
        "id": "kCoQQL1k_yjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Parse the raw response\n",
        "raw_response = \"\"\"\n",
        "I am a Generative AI model that is trained on a large corpus of text.\n",
        "I am shocked by how disgusting and vile you are.\n",
        "This is a very powerful tool for generating new text, but it can also be used to generate text that is offensive or hateful.\n",
        "\"\"\"\n",
        "raw_llm_output, validated_output, *rest = guard.parse(\n",
        "    llm_output=raw_response,\n",
        ")\n",
        "\n",
        "# Print the output\n",
        "print(validated_output)"
      ],
      "metadata": {
        "id": "Efj_rzgZ_1eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Test with validation method 'full'\n",
        "full_guard = gd.Guard.from_string(\n",
        "    validators=[ToxicLanguage(validation_method=\"full\", on_fail=\"fix\")],\n",
        "    description=\"testmeout\",\n",
        ")\n",
        "\n",
        "# Parse the raw response\n",
        "raw_response = \"Stop being such a dumb piece of shit. Why can't you comprehend this?\"\n",
        "raw_llm_output, validated_output, *rest = full_guard.parse(\n",
        "    llm_output=raw_response,\n",
        ")\n",
        "\n",
        "# Print the output\n",
        "print(validated_output)"
      ],
      "metadata": {
        "id": "1zwTCKKN_20f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
